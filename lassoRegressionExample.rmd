---
title: "Penalized Lasso Regression"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(tidyverse)
library(caret)
library(glmnet)
library(mlbench)
```

Load the data and remove NAs
```{r}
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
sample_n(PimaIndiansDiabetes2, 3)
# Split the data into training and test set
set.seed(123)
training.samples <- PimaIndiansDiabetes2$diabetes %>% 
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- PimaIndiansDiabetes2[training.samples, ]
test.data <- PimaIndiansDiabetes2[-training.samples, ]
```
Additional data preperations, convert model.matrx to handle predictors
```{r}
# Dummy code categorical predictor variables
x <- model.matrix(diabetes~., train.data)[,-1]
# Convert the outcome (class) to a numerical variable, set pos as 1, neg as 0 
y <- ifelse(train.data$diabetes == "pos", 1, 0)
```
Use glmnet for computing penalized logistic regression 
x: the matrix of just predictor variables 
y: the response or outcome variables (should be binomial for outcome var)
family: the response type <-- binomial for binary outcome variable 
alpha: elasticnet mixing param 
  1: for lasso regression
  0: for ridge regression 
  0<x<1: for elastic net regression 
  lambda: a numeric value defining the amount of shrinkage. The best Lambda for your data can be defined as the lambda that minimze the corss-valdiation prediction error rate, can be done using cv.glmnet()
```{r}
set.seed(123)
# Alpha = 1 indicates lasso regression 
cv.lasso<- cv.glmnet(x,y,alpha=1, family = "binomial")
model <- glmnet(x,y, alpha =1, family = "binomial", lambda = cv.lasso$lambda.min)
# Display the regression coefficients
coef(model)
x.test <- model.matrix(diabetes ~., test.data)[,-1]
probabilities <- model %>% predict(newx = x.test)
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
# Model accuracy
observed.classes <- test.data$diabetes
mean(predicted.classes == observed.classes)
```

```{r}
# Compute Optimal value of lambda 
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
plot(cv.lasso)
```
```{r}
cv.lasso$lambda.min
```
```{r}
cv.lasso$lambda.1se
```

